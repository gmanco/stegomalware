

import matplotlib.pyplot as plt
import os
import sys

import torch
import torch.nn as nn
import torch.nn.functional as F

import torchvision.datasets as datasets
import torchvision.transforms as transforms
from torch.utils.data import Dataset

from time import time
from tqdm import tqdm

import numpy as np
from PIL import Image
import natsort

from model import AutoEncoder

device = torch.device("cuda:0" if (torch.cuda.is_available()) else "cpu")



def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)


class DenoiseLoss(nn.Module):
    def __init__(self):
        super(DenoiseLoss, self).__init__()

        self.criterion = nn.BCELoss()
        self.bern_crit = torch.nn.BCEWithLogitsLoss()

    def forward(self, x, y):
        return self.criterion(x.flatten(), y.flatten())

class Trainer():
    def __init__(self, device):
        self.device = device
        self.model = AutoEncoder(3).to(self.device)
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)
        self.loss_criterion = DenoiseLoss()

    def step(self, x, y):
        self.model.zero_grad()

        y_rec = self.model(x)
        loss_batch = self.loss_criterion(y_rec, y)

        loss_batch.backward()
        self.optimizer.step()

        return loss_batch

    def train(self, data_loader, batch_size=32, num_epochs=10, step=100):
        losses = np.zeros(num_epochs)

        total_steps = (len(data_loader.dataset) // batch_size)  # *num_epochs
        print("[INFO] Starting training phase...")
        start = time()

        try:
            step_count = 0
            for epoch in range(num_epochs):
                i = 0
                for x_batch, y_batch in data_loader:
                    i += 1
                    step_count += 1
                    x_batch = x_batch.to(self.device)
                    y_batch = y_batch.to(self.device)

                    ### Train autoencoder ###
                    loss = self.step(x_batch,y_batch)

                    losses[epoch] = losses[epoch] * (i / (i + 1.)) + loss.item() * (1. / (i + 1.))

                    if (i + 1) % step == 0:
                        sys.stdout.write(
                            "\r" + 'Epoch [{:>3}/{}] | Step [{:>3}/{}]| loss: {:.4f} |'
                            .format(epoch + 1, num_epochs, i + 1, total_steps, loss.item()))
                        sys.stdout.flush()
        except KeyboardInterrupt:
            print('-' * 89)
            print('[INFO] Exiting from training early')
        print(f'\n[INFO] Training phase... Elapsed time: {(time() - start):.0f} seconds\n')
        return losses[:epoch]




batch_size = 4
epochs = 1000

print("[INFO] loading dataset...")

transform = transforms.Compose([transforms.ToTensor()])

class CustomDataset(Dataset):
    def __init__(self, main_dir, transform):
        self.main_dir = main_dir
        self.transform = transform
        all_imgs = os.listdir(os.path.join(main_dir,'malware'))
        self.total_imgs = natsort.natsorted(all_imgs)

    def __len__(self):
        return len(self.total_imgs)

    def __getitem__(self, idx):
        mal_img_loc = os.path.join(self.main_dir, 'malware', self.total_imgs[idx])
        malware_image = Image.open(mal_img_loc).convert("RGB")
        tensor_mal_image = self.transform(malware_image)
        t = self.total_imgs[idx].find('_') + 1
        clean_img_log = os.path.join(self.main_dir, 'clean', self.total_imgs[idx][t:])
        clean_image = Image.open(clean_img_log).convert("RGB")
        tensor_clean_image = self.transform(clean_image)
        return tensor_mal_image, tensor_clean_image

train_set = CustomDataset('./data/train', transform=transform)
test_set = CustomDataset('./data/test', transform=transform)
train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)


model = Trainer(device)
losses = model.train(train_loader, batch_size=batch_size, num_epochs=epochs)

# Save the model checkpoints
torch.save(model.model.state_dict(), './model.ckpt')



num_epochs = len(losses)

plt.figure(figsize=(15, 10))
plt.xlim(0, num_epochs + 1)
plt.plot(range(1, num_epochs + 1), losses[:num_epochs], label='loss')
plt.legend()
plt.show()


